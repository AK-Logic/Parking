{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f19d3a33",
   "metadata": {},
   "source": [
    "# Parking Sign Recognition\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54a8608e",
   "metadata": {},
   "source": [
    "### Steps\n",
    "\n",
    "1. pictures of every possible sign [doesn't need words]\n",
    "2. need to find python library to do the following a) Recognize the sign object b) match the sign with our database of base signs c) read the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96ea567",
   "metadata": {},
   "source": [
    "To Do step 2a, we are going to attempt to use opencv\n",
    "First, pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7f88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #opencv is cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bb4067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube tut: https://www.youtube.com/watch?v=T-0lZWYWE9Y&list=PLzMcBGfZo4-lUA8uGjeXhBUUzPYc6vZRn&index=7\n",
    "\n",
    "# Loading Images\n",
    "# imread has a second paramter of -1, 0 or 1\n",
    "# -1: loads a colored image, neglecting transparency (default)\n",
    "# 0: loads image in grayscale\n",
    "# 1: includes image as it is, including transparency\n",
    "\n",
    "imgt1 = cv2.imread('Parking Signs/Base Signs/no standing.jpg', 0) #imgt1 for image template1\n",
    "img1 = cv2.imread('Parking Signs/Signs/cams house.jpg', 0) #img1, this is the image we will run template again.\n",
    "img1 = cv2.resize(img1, (800,800)) # This image was way too big initially\n",
    "\n",
    "# These next 3 lines displays the image\n",
    "cv2.imshow('template1',imgt1) # you need the next two lines to run this\n",
    "cv2.waitKey(0) # Waits a number of seconds until we press a key to move onto the next line, 0 indicates to wait infinitely\n",
    "cv2.destroyAllWindows() # closes the image\n",
    "cv2.imshow('image1',img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "\n",
    "# images are understood by python as numpy arrays representing 3 values per pixel [blue, green, red] where blue green red represent a number from 0-255\n",
    "# the columns represent the width while the rows represent the height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aac2b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To recognize a sign, we can use corner detection (shi-thomasi Detector & goodFeaturesToTrack()). This may be problematic by picking up other corners in an image\n",
    "# however this does allow you to specify a few paramaters to help improve accuracy. \n",
    "# Paramaters are: (input image, # of best corners to choose, confidence level, min euclidean distance between corners)\n",
    "\n",
    "# Template matching is likely the algorithm to use. A potential issue is that the size of the template image needs to be close enough to the size in the actual image.\n",
    "# In our case we are going to try and match pictures in Base Signs to picutres in Signs folder.\n",
    "# This algorithm requires grayscale. Note that since we are using grayscale now instead of a 3 dimensional array [height, width, channel], its just [height, width]\n",
    "# 6 different methods to template match. It is recommended to try each method and figure out which gets the best results.\n",
    "# The methods are TM_CCOEFF, TM_CCOEFF_NORMED, TM_CCORR, TM_CCORR_NORMED, TM_SQDIFF, TM_SQDIFF_NORMED\n",
    "\n",
    "methods = [cv2.TM_CCOEFF, cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR, cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]\n",
    "\n",
    "h, w = imgt1.shape\n",
    "\n",
    "# loop through all methods and find the best one\n",
    "for method in methods:\n",
    "    img2 = img1.copy()\n",
    "    \n",
    "    result = cv2.matchTemplate(img2, imgt1, method) # this performs a convolution. In other words, it slides img2 all around imgt1 until it finds a reasonable match.\n",
    "                                            # this returns a 2 dimension array telling us how confident of a match there is in each region of the image\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result) # we case about min_loc, max_loc. These are the locations with best match. Max or min is best, depending on the method.\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        location = min_loc\n",
    "    else:\n",
    "        location = max_loc\n",
    "\n",
    "    bottom_right = (location[0] + w, location[1] + h)\n",
    "    cv2.rectangle(img2, location, bottom_right, 255, 5) # We draw a rectangle at the location, 255 for black, line thickness 5\n",
    "    cv2.imshow('Match', img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows() # Seems like method 1 is the only one that works for this example. Size of both images is very important. Need to figure out best sizing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
